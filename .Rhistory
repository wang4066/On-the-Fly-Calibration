(bias=mean((est.thetas31-true.thetas)))
(mse<-mean((est.thetas31-true.thetas)^2)) #0.03136919
cor(est.thetas31,true.thetas)
plot(est.thetas,true.thetas,xlim=c(-4,4),ylim=c(-4,4))
test.items<-response<-interim.theta<-matrix(,N,L)
####Start of the loop ####
for(i in 1:N) {
item.temp<-est.temp<-est.mat<-NULL
selected.items<-rep(1,J)
# select the first 5 items randomly
initial.items=5
item.temp<-test.items[i,1:initial.items]<-sample(1:J,initial.items)
#item.temp<-test.items[i,1:initial.items]<-item.select(true.thetas[i],selected.items)
selected.items[item.temp]<-0
#simulate response to the first 5 item and estimate theta
#set.seed(1)
response[i,1:initial.items]=resp.mat[i,item.temp]#res.gen(initial.items,true.thetas[i],item.bank[item.temp,2])
#estimate theta with all the current responses made
response.temp<-response[i,1:initial.items,drop=F]
test.temp<-test.items[i,1:initial.items]
ip<-item.bank[test.temp,,drop=F]
interim.theta[i,initial.items]<-theta.est(response.temp[1,],ip[,2])
#from sixth to the last item
converge=0
l=initial.items+1 #converge == 0  &&
while(l<51){
item.temp<-test.items[i,l]<-item.select(interim.theta[i,(l-1)],selected.items)
selected.items[item.temp]<-0
#simulate response for this item
#set.seed(1)
response[i,l]=resp.mat[i,item.temp]#res.gen(1,true.thetas[i],item.bank[item.temp,2])
response.temp<-response[i,1:l,drop=F]
test.temp<-test.items[i,1:l]
ip<-item.bank[test.temp,,drop=F]
interim.theta[i,l]<-theta.est(response.temp[1,],ip[,2])
l=l+1
}
}
est.thetas<-interim.theta[,L]
(bias=mean((est.thetas-true.thetas))) #-0.006816922
(mse<-mean((est.thetas-true.thetas)^2)) # 0.2658372
(corrTE=cor(est.thetas,true.thetas)) # 0.8647478
for (i in 1:N){
b.mat[i,]= item.bank[test.items[i,],2]
}
est.thetas31<-vector(,N)
response31<-matrix(0,N,L)
for(i in 1:N){
item.temp=test.items[i,]
response31[i,]= resp.mat[i,item.temp]#res.gen(L,true.thetas[i],b.mat[i,])#response[i,]
#set.seed(1)
#response31[i,1:5]=res.gen(5,true.thetas[i],b.mat[i,1:5])
#  for(jj in 1:50){
#set.seed(1)
#    response31[i,jj]=res.gen(1,true.thetas[i],b.mat[i,jj])
#  }
#  response31[i,]=res.gen(L,true.thetas[i],b.mat[i,])
est.thetas31[i]<-theta.est(response31[i,],b.mat[i,])
}
(bias=mean((est.thetas31-true.thetas)))
(mse<-mean((est.thetas31-true.thetas)^2)) #0.03136919
cor(est.thetas31,true.thetas)
est.thetas31<-vector(,N)
response31<-matrix(0,N,L)
for(i in 1:N){
item.temp=test.items[i,]
#  response31[i,]= resp.mat[i,item.temp]#res.gen(L,true.thetas[i],b.mat[i,])#response[i,]
#set.seed(1)
#response31[i,1:5]=res.gen(5,true.thetas[i],b.mat[i,1:5])
#  for(jj in 1:50){
#set.seed(1)
#    response31[i,jj]=res.gen(1,true.thetas[i],b.mat[i,jj])
#  }
response31[i,]=res.gen(L,true.thetas[i],b.mat[i,])
est.thetas31[i]<-theta.est(response31[i,],b.mat[i,])
}
(bias=mean((est.thetas31-true.thetas)))
(mse<-mean((est.thetas31-true.thetas)^2)) #0.03136919
cor(est.thetas31,true.thetas)
est.thetas31<-vector(,N)
response31<-matrix(0,N,L)
for(i in 1:N){
item.temp=test.items[i,]
#  response31[i,]= resp.mat[i,item.temp]#res.gen(L,true.thetas[i],b.mat[i,])#response[i,]
#set.seed(1)
#response31[i,1:5]=res.gen(5,true.thetas[i],b.mat[i,1:5])
#  for(jj in 1:50){
#set.seed(1)
#    response31[i,jj]=res.gen(1,true.thetas[i],b.mat[i,jj])
#  }
response31[i,]=res.gen(L,true.thetas[i],b.mat[i,])
est.thetas31[i]<-theta.est(response31[i,],b.mat[i,])
}
(bias=mean((est.thetas31-true.thetas)))
(mse<-mean((est.thetas31-true.thetas)^2)) #0.03136919
cor(est.thetas31,true.thetas)
resp.mat2=matrix(0,N,J)
for (i in 1:N){
resp.mat2[i,]=res.gen(J,true.thetas[i],item.bank[,2])
}
est.thetas31<-vector(,N)
response31<-matrix(0,N,L)
for(i in 1:N){
item.temp=test.items[i,]
response31[i,]= resp.mat2[i,item.temp]#res.gen(L,true.thetas[i],b.mat[i,])#response[i,]
#set.seed(1)
#response31[i,1:5]=res.gen(5,true.thetas[i],b.mat[i,1:5])
#  for(jj in 1:50){
#set.seed(1)
#    response31[i,jj]=res.gen(1,true.thetas[i],b.mat[i,jj])
#  }
#  response31[i,]=res.gen(L,true.thetas[i],b.mat[i,])
est.thetas31[i]<-theta.est(response31[i,],b.mat[i,])
}
(bias=mean((est.thetas31-true.thetas)))
(mse<-mean((est.thetas31-true.thetas)^2)) #0.03136919
cor(est.thetas31,true.thetas)
resp.mat2=matrix(0,N,J)
for (i in 1:N){
resp.mat2[i,]=res.gen(J,true.thetas[i],item.bank[,2])
}
est.thetas31<-vector(,N)
response31<-matrix(0,N,L)
for(i in 1:N){
item.temp=test.items[i,]
response31[i,]= resp.mat2[i,item.temp]#res.gen(L,true.thetas[i],b.mat[i,])#response[i,]
#set.seed(1)
#response31[i,1:5]=res.gen(5,true.thetas[i],b.mat[i,1:5])
#  for(jj in 1:50){
#set.seed(1)
#    response31[i,jj]=res.gen(1,true.thetas[i],b.mat[i,jj])
#  }
#  response31[i,]=res.gen(L,true.thetas[i],b.mat[i,])
est.thetas31[i]<-theta.est(response31[i,],b.mat[i,])
}
(bias=mean((est.thetas31-true.thetas)))
(mse<-mean((est.thetas31-true.thetas)^2)) #0.03136919
cor(est.thetas31,true.thetas)
est.thetas31<-vector(,N)
response31<-matrix(0,N,L)
for(i in 1:N){
item.temp=test.items[i,]
response31[i,]= resp.mat[i,item.temp]#res.gen(L,true.thetas[i],b.mat[i,])#response[i,]
#set.seed(1)
#response31[i,1:5]=res.gen(5,true.thetas[i],b.mat[i,1:5])
#  for(jj in 1:50){
#set.seed(1)
#    response31[i,jj]=res.gen(1,true.thetas[i],b.mat[i,jj])
#  }
#  response31[i,]=res.gen(L,true.thetas[i],b.mat[i,])
est.thetas31[i]<-theta.est(response31[i,],b.mat[i,])
}
(bias=mean((est.thetas31-true.thetas)))
(mse<-mean((est.thetas31-true.thetas)^2)) #0.03136919
cor(est.thetas31,true.thetas)
42/sqrt(2)
library(glmnet)
data("QuickStartExample")
View(x)
View(x)
data(SparseExample)
class(x)
head(x)
X = matrix(rnorm(20), 10, 2)
X
X[3, 1] = NA
X[5, 2] = NA
X3 = sample(letters[1:3], 10, replace = TRUE)
X3[6] = NA
X4 = sample(LETTERS[1:3], 10, replace = TRUE)
X4[9] = NA
dfn = data.frame(X, X3, X4)
View(dfn)
log(0.0147554)
library(softImpute)
install.packages("softImpute")
library(softImpute)
set.seed(101)
n=200
p=100
J=50
np=n*p
missfrac=0.3
x=matrix(rnorm(n*J),n,J)%*%matrix(rnorm(J*p),J,p)+matrix(rnorm(np),n,p)/5
ix=seq(np)
View(x)
imiss=sample(ix,np*missfrac,replace=FALSE)
xna=x
xna[imiss]=NA
View(xna)
fit1=softImpute(xna,rank=50,lambda=30)
complete(xna,fit1)
View(fit1)
View(xna)
completex=complete(xna,fit1)
View(completex)
375*0.7
require(softImpute)
set.seed(1011)
x=matrix(rnorm(30),6,5)
x[sample(1:30,10,replace=FALSE)]=NA
x
fits=softImpute(x,trace=TRUE,type="svd")
View(x)
completex=complete(x,fits)
View(completex)
install.packages("missMDA")
estim_ncpPCA
source_url('https://raw.githubusercontent.com/R-miss-tastic/website/master/static/how-to/generate/amputation.R')
?source.url
source.url('https://raw.githubusercontent.com/R-miss-tastic/website/master/static/how-to/generate/amputation.R')
install.packages(c("gdata", "LiblineaR", "mltools"))
9*0.15-0.6
0.75/9
sqrt(0.04*3)
sqrt(0.09*2)
load("C:/Users/wangc/Dropbox/Active Projects/NIH Mayo project/Real Data analysis/Final item bank/itembank.Rda")
itembank$params
mean(itembank$params)
colmeans(itembank$params)
ColMeans(itembank$params)
ColMeans(itembank$params)
colMeans(itembank$params)
1.107*1.7
2.08*1.75
2.08*1.7
6.13、1.05
6.13/1.05
15/(35*34/2)
3.75/1.7
qchisq(.95, df=3471)
qchisq(.95, df=4438)
qchisq(.95, df=6178)
qchisq(.95, df=2762)
qchisq(.95, df=3889)
qchisq(.99, df=3889)
qchisq(.95, df=4432)
qchisq(.95, df=4339)
qchisq(.95, df=2474)
qchisq(.95, df=3975)
qchisq(.95, df=4719)
12*18
12*12
library(ProcData)
library(keras)
install.packages("ProcData",dependencies=T)
library(ProcData)
updateR()
library(installr)
updateR()
library(installr)
updateR()
install.packages("ProcData", dependencies=T)
library(keras)
install_keras(tensorflow="1.13.1")
mnist <- dataset_mnist()
library(ProcData)
library(keras)
install_keras(tensorflow="1.13.1")
mnist <- dataset_mnist()
install.packages("corrplot")
mnist <- dataset_mnist()
install_keras(tensorflow="1.13.1")
rm(list=ls())
library("ProcData")
Sys.which("make")
library(keras)
install_keras(tensorflow="1.13.1")
mnist <- dataset_mnist()
install.packages("tensorflow=1.13.1")
mnist <- dataset_mnist()
install_keras(tensorflow="1.13.1")
install_keras(tensorflow="1.13.1")
install.packages("tensorflow=1.13.1")
library(keras)
install_keras(tensorflow="1.13.1")
mnist <- dataset_mnist()
mnist <- dataset_mnist()
use_condaenv("r-tensorflow")
mnist <- dataset_mnist()
library(tensorflow)
mnist <- dataset_mnist()
library("ProcData")
# install.packages("corrplot", dependencies = TRUE)
library(corrplot)
library(keras)
install.packages("tensorflow=1.13.1")
install_keras(tensorflow="1.13.1")
$ conda update -n base -c defaults conda
conda update -n base -c defaults conda
mnist <- dataset_mnist()
install_keras(tensorflow)
install_keras(tensorflow)
install.packages(tensorflow)
install.packages("tensorflow")
install.packages("tensorflow")
install_keras(tensorflow)
install_keras(tensorflow="1.13.1")
library(keras)
install_keras(tensorflow="1.13.1")
mnist <- dataset_mnist()
install.packages("ProcData", dependencies=T)
install.packages("keras")
library(keras)
install_keras(tensorflow="1.13.1")
mnist <- dataset_mnist()
mnist <- dataset_mnist()
library("ProcData")
# install.packages("corrplot", dependencies = TRUE)
library(corrplot)
library(keras)
install_keras(tensorflow="1.13.1")
mnist <- dataset_mnist()
mnist <- dataset_mnist()
install.packages("learnr", dependencies = T)
install.packages("glmnet", dependencies = T)
install.packages("mirt", dependencies = T)
install.packages('inline', dependencies = T)
mnist <- dataset_mnist()
mnist <- dataset_mnist()
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/keras")
install.packages("devtools")
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/keras")
library("ProcData")
# install.packages("corrplot", dependencies = TRUE)
library(corrplot)
library(keras)
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/keras")
devtools::install_github("rstudio/keras")
library(devtools)
devtools::install_github("xytangtang/ProcData", dependencies=T)
library("ProcData")
# install.packages("corrplot", dependencies = TRUE)
library(corrplot)
library(keras)
install_keras()
# install_keras(tensorflow="1.13.1")
# mnist <- dataset_mnist()
mnist <- dataset_mnist()
# extract 10 features from the provided response processes
mds_res0 <- seq2feature_mds(seqs = cc_seqs, K = 5)
data("cc_data")
# cc_data is a list of two elements
names(cc_data)
# element seqs is an object of class "proc". It contains the response
# processes of 16,763 participants
class(cc_data$seqs)
# element responses is a binary vector containing the item responses
# 1: correct 0: incorrect
length(cc_data$responses)
table(cc_data$responses)
########################################################################
###                code chunk number 3: class "proc"                 ###
########################################################################
### This code chunk demonstrates S3 class "proc" for processes data. ###
########################################################################
# An object of class "proc" is a list of two elements.
#    action_seqs: a list of character vectors (action sequences)
#    time_seqs: a list of numeric vectors (timestamp sequences)
class(cc_data$seqs)
names(cc_data$seqs)
# print method of class "proc".
# print.proc prints first 5 processes by default.
cc_data$seqs
set.seed(1234)
n <- 1000
idx <- sample(1:cc_summary$n_seq, n)
cc_seqs <- sub_seqs(cc_data$seqs, idx)
y <- cc_data$responses[idx]
# remove repeated actions in action sequences
cc_seqs <- remove_repeat(cc_seqs)
data("cc_data")
# cc_data is a list of two elements
names(cc_data)
# element seqs is an object of class "proc". It contains the response
# processes of 16,763 participants
class(cc_data$seqs)
# element responses is a binary vector containing the item responses
# 1: correct 0: incorrect
length(cc_data$responses)
table(cc_data$responses)
########################################################################
###                code chunk number 3: class "proc"                 ###
########################################################################
### This code chunk demonstrates S3 class "proc" for processes data. ###
########################################################################
# An object of class "proc" is a list of two elements.
#    action_seqs: a list of character vectors (action sequences)
#    time_seqs: a list of numeric vectors (timestamp sequences)
class(cc_data$seqs)
names(cc_data$seqs)
# print method of class "proc".
# print.proc prints first 5 processes by default.
cc_data$seqs
# print first n processes
print(cc_data$seqs, n=5)
# you can specify the indices of processes to print.
print(cc_data$seqs, index=3)
print(cc_data$seqs, index=c(4,5))
# summary method of class "proc"
cc_summary <- summary(cc_data$seqs)
# It returns a list of summary statistics of processes
names(cc_summary)
# number of processes
cc_summary$n_seq
# number of unique actions
cc_summary$n_action
# action set
sort(cc_summary$actions) # action set
#  process length
range(cc_summary$seq_length) # range of sequence lengths
# action frequency
sort(cc_summary$action_freq / sum(cc_summary$action_freq), decreasing=TRUE)[1:10]
# action sequence frequency
sort(cc_summary$action_seqfreq / cc_summary$n_seq, decreasing = TRUE)[1:10]
# action transition probability matrix
trans_mat <- cc_summary$trans_count
dim(trans_mat)
trans_mat <- trans_mat / rowSums(trans_mat)
# randomly select 25 actions to plot the transition matrix
idx_plot <- sample(1:cc_summary$n_action, 25)
corrplot(trans_mat[idx_plot, idx_plot],
is.corr = FALSE, cl.lim = c(0, 1),
tl.cex = 0.75, na.label = " ")
# summary of total time
cc_summary$total_time
# summary of mean reaction time
cc_summary$mean_react_time
########################################################################
###              code chunk number 4: data processing                ###
########################################################################
### This part demonstrates five functions for data processing.       ###
########################################################################
# subset "proc" objects
seqs <- sub_seqs(cc_data$seqs, 4*1:10)
seqs
print(seqs, 1)
# remove repeated actions
seqs1 <- remove_repeat(seqs)
print(seqs1, 1)
# remove actions
seqs2 <- remove_action(seqs1, "0_0_0")
print(seqs2, 1)
# replace actions
seqs3 <- replace_action(seqs2, "reset", "RESET")
print(seqs3, 1)
# combine actions
seqs4 <- combine_actions(seqs2, c("0_0_1", "0_0_2"), "BOTTOM_MOVE_ONE")
print(seqs4, 1)
# Now let's process climate control data for later use.
# subset dataset
set.seed(1234)
n <- 1000
idx <- sample(1:cc_summary$n_seq, n)
cc_seqs <- sub_seqs(cc_data$seqs, idx)
y <- cc_data$responses[idx]
# check proportion of correct answers
table(y)
mean(y)
# remove repeated actions in action sequences
cc_seqs <- remove_repeat(cc_seqs)
# extract 10 features from the provided response processes
mds_res0 <- seq2feature_mds(seqs = cc_seqs, K = 5)
names(mds_res0)
dim(mds_res0$theta)
# select feature dimension K by cross-validation
mds_cv_res <- chooseK_mds(seqs = cc_seqs, K_cand = c(20, 50), n_fold = 3,
return_dist = TRUE)
mds_cv_res$K_cand
# pass the computed dissimilarity matrix to seq2feature_mds
mds_res <- seq2feature_mds(seqs = mds_cv_res$dist_mat, K = mds_cv_res$K)
plot(mds_res$theta[,1:2], xlab="feature 1", ylab="feature 2", pch=16, cex=0.7)
n_train <- n*0.8
n_test <- n - n_train
index_train <- sample(1:n, n_train)
index_test <- setdiff(1:n, index_train)
# fit a logistic regression model using the training set
mds_data <- data.frame(y = y, x = mds_res$theta)
mds_glm_res <- glm(y ~ ., family = "binomial",
subset=index_train, data=mds_data)
seqs <- seq_gen(50, include_time=TRUE)
# consider action sequences only first
# select feature dimension by cross-validation
cv_res <- chooseK_seq2seq(seqs = seqs, ae_type = "action",
K_cand = c(3, 5), rnn_type="gru",
n_fold = 2, n_epoch = 5)
names(cv_res)
cv_res$K
(9*0.02+1.5)/12
(9*0.05+1)/12
2/12
(9*0.15+1.5)/12
(9*0.15+1)/12
12*0.14
(9*0.15+1)
(9*0.15+1)/12
(9*0.02+1)/12
(9*0.02+1)
12*0.24
12*19.58/100
pchisq(4170.71, df=4438)
pchisq(7548.668, df=4719)
qchisq(.99, df=4438)
qchisq(.99, df=4719)
qchisq(.95, df=4438)
install.packages(doSNOW)
install.packages("doSNOW")
library(doSNOW)
setwd("C:/Users/wangc/Dropbox/Active Projects/Efficient online calibration_Shengyu/On-the-Fly-Calibration")
